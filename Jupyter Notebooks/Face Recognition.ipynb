{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce92c09-9934-4f8e-9ad4-8f17838523d9",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20351f41-0b14-4907-9f08-66444f5e625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d9949b-c924-47e7-8aa9-fb8a63dd5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Scale Function\n",
    "def scaleFrame(frame,scale=0.75):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions =  (width,height)\n",
    "\n",
    "    return cv.resize(frame,dimensions,interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883d1148-2612-48c4-a612-3ba1e85dc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setImageDimension(frame):\n",
    "    dimensions =  (150,150)\n",
    "    return cv.resize(frame,dimensions,interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95b6470-adb3-4e8a-8462-80bd071bd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing box and writing Name with Confidence\n",
    "def faceBox(image,x,y,width,height,label,confidence):\n",
    "    cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    cv.putText(image, 'Person {} : {}%'.format(label,confidence), (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066998e7-9572-474a-892e-7d8fdfc8fd20",
   "metadata": {},
   "source": [
    "# Training the recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972c8101-3a00-4863-ac81-d58d97097880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_and_labels(dataset_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for person_dir in os.listdir(dataset_path):\n",
    "        person_path = dataset_path+\"/\"+person_dir\n",
    "        if os.path.isdir(person_path):\n",
    "            for image_name in os.listdir(person_path):\n",
    "                image_path = person_path+\"/\"+image_name\n",
    "                image = cv.imread(image_path,cv.IMREAD_GRAYSCALE)\n",
    "                images.append(image)\n",
    "                labels.append(int(person_dir))  # Use folder name as label\n",
    "\n",
    "    return images, labels\n",
    "    \n",
    "recognizer =  cv.face.EigenFaceRecognizer_create()\n",
    "image_paths, labels = get_images_and_labels(\"C:/Users/mohit/Programming/My_Projects/Attendance System Using Face Recognition/Dataset\")\n",
    "# print(labels)\n",
    "recognizer.train(image_paths, np.array(labels))\n",
    "recognizer.write(\"./../Face_Recognizer.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068ce1e-28fe-4955-889b-802db9201483",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83ff26-3b88-43e6-906c-0c6a2f70fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the recognizer\n",
    "recognizer = cv.face.EigenFaceRecognizer_create()\n",
    "recognizer.read(\"./../Face_Recognizer.xml\")\n",
    "\n",
    "# Face Detection Using CascadeClassifier\n",
    "videoStream = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturing Frame from camera\n",
    "    isRet, frame = videoStream.read()\n",
    "\n",
    "    # Scaling Image\n",
    "    frame = scaleFrame(frame,scale=1.35)\n",
    "\n",
    "    # Converting frame to gray scale\n",
    "    gray_frame = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Loading face detector from opencv library\n",
    "    face_detector_frontal = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    face_detector_profile = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_profileface.xml\")\n",
    "\n",
    "    # Detecting Faces\n",
    "    face_frontal = face_detector_frontal.detectMultiScale(gray_frame, minNeighbors=10, minSize=(30,30))\n",
    "    face_profile = face_detector_profile.detectMultiScale(gray_frame, minNeighbors=10, minSize=(30,30))\n",
    "\n",
    "    # Creating Box Around Face\n",
    "    if len(face_frontal) > 0:\n",
    "        for (x, y, w, h) in face_frontal:\n",
    "            face = gray_frame[y:y+h, x:x+w]\n",
    "            face = setImageDimension(face)\n",
    "            label,confidence = recognizer.predict(face)\n",
    "            frame = faceBox(frame,x,y,w,h,label,confidence)\n",
    "    elif len(face_profile) > 0:\n",
    "        for (x, y, w, h) in face_profile:\n",
    "            face = gray_frame[y:y+h, x:x+w]\n",
    "            face = setImageDimension(face)\n",
    "            label,confidence = recognizer.predict(face)\n",
    "            frame = faceBox(frame,x,y,w,h,label,confidence)\n",
    "\n",
    "    # Displaying Image\n",
    "    cv.imshow(\"Face Recognition\",frame)\n",
    "\n",
    "    # Checking for keyboard input to \n",
    "    if cv.waitKey(3) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "videoStream.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
